{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List algorithms\n",
    "\n",
    "For each challenge here, first write the algo in pseudo code. then implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear search\n",
    "```python\n",
    "robbers = ['Tokyo', 'Professor', 'Lisbon', 'Oslo', 'Helsinki', 'Rio', 'Moscow', 'Berlin', 'Palermo']\n",
    "linear_search(robbers, 'Professor') == 1\n",
    "linear_search(robbers, 'alon') == -1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robbers = ['Tokyo', 'Professor', 'Lisbon', 'Oslo', 'Helsinki', 'Rio', 'Moscow', 'Berlin', 'Palermo']\n",
    "\n",
    "def linear_search(sequence:list, target)-> int:\n",
    "    for idx, item in enumerate(sequence):\n",
    "        if item == target:\n",
    "            return idx\n",
    "    return -1\n",
    "\n",
    "assert linear_search(robbers, 'Lisbon') == 2\n",
    "len(robbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisting the big O notation\n",
    "\n",
    ">Big O notation describes the **complexity of your code using algebraic terms.**\n",
    "\n",
    "So what is the big O notation for our linear_search?\n",
    "1. How many steps it would take in the worse case?\n",
    "2. How many would it take in the best case?\n",
    "\n",
    "[Read more about big O](https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's tackle a more real life problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab = [\"apple\", \"boy\", \"dog\", \"down\",\n",
    "                          \"fell\", \"girl\", \"grass\", \"the\", \"tree\"]\n",
    "book_words = \"the apple fell from the tree to the grass\".split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unknown_words(vocab:list, book_words:list):\n",
    "    # Use linear search\n",
    "    result = []\n",
    "    for word in book_words:\n",
    "        \n",
    "        if linear_search(vocab, word) < 0: \n",
    "            result.append(word)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert find_unknown_words(vocab, book_words) == [\"from\", \"to\"]\n",
    "assert find_unknown_words([], book_words) == book_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you implement `find_unknown_words` using the linear_Search we've built before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but for lets try with a bigger vocab\n",
    "\n",
    "def load_words_from_file(filename):\n",
    "    \"\"\" Read words from filename, return list of words. \"\"\"\n",
    "    f = open(filename, \"r\")\n",
    "    file_content = f.read()\n",
    "    f.close()\n",
    "    wds = file_content.split()\n",
    "    return wds\n",
    "\n",
    "bigger_vocab = load_words_from_file(\"vocab.txt\")\n",
    "len(bigger_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading words from a book with need some normalization\n",
    "\n",
    "def text_to_words(the_text):\n",
    "    \"\"\" return a list of words with all punctuation removed,\n",
    "        and all in lowercase.\n",
    "    \"\"\"\n",
    "\n",
    "    my_substitutions = the_text.maketrans(\n",
    "      # If you find any of these\n",
    "      \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\\\"#$%&()*+,-./:;<=>?@[]^_`{|}~'\\\\\",\n",
    "      # Replace them by these\n",
    "      \"abcdefghijklmnopqrstuvwxyz                                          \")\n",
    "\n",
    "    # Translate the text now.\n",
    "    cleaned_text = the_text.translate(my_substitutions)\n",
    "    wds = cleaned_text.split()\n",
    "    return wds\n",
    "\n",
    "\n",
    "def get_words_in_book(filename):\n",
    "    \"\"\" Read a book from filename, and return a list of its words. \"\"\"\n",
    "    f = open(filename, \"r\")\n",
    "    content = f.read()\n",
    "    f.close()\n",
    "    wds = text_to_words(content)\n",
    "    return wds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert text_to_words('\"Well, I never!\", said Alice.') ==  [\"well\", \"i\", \"never\", \"said\", \"alice\"]\n",
    "# How we can implement text to words?\n",
    "# Note you should use split and probably replace or python translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27336"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting back to big O\n",
    "len(get_words_in_book('alice_in_wonderland.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.process_time()\n",
    "vocab = vocab.extend(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta 45.548922968\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "alice_words = get_words_in_book('alice_in_wonderland.txt')\n",
    "vocab = load_words_from_file('vocab.txt')\n",
    "vocab.extend(vocab)\n",
    "vocab.extend(vocab)\n",
    "\n",
    "start = time.process_time() \n",
    "find_unknown_words(vocab, alice_words)\n",
    "end = time.process_time()\n",
    "print(f\"Delta {end-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happened here? \n",
    "* Seeing big O notation in action\n",
    "* What could we do differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The road not taken\n",
    "\n",
    "* Before we go and implement our own version of search let's explore other options *\n",
    "\n",
    "### What else could we do? \n",
    "\n",
    "So after we explored some more \"pythonic\" solutions, let's go back into implementig an classic algorithmic solution - Binary search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unknown_words_pythonic(vocab:list, book_words:list):\n",
    "    # Use linear search\n",
    "    results = []\n",
    "    for word in book_words:\n",
    "        \n",
    "        if word not in vocab: \n",
    "            results.append(word)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta 11.822740701999997\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### now let's check the difference between our previous linear algo and the new algo\n",
    "start = time.process_time() \n",
    "find_unknown_words_pythonic(vocab, alice_words)\n",
    "end = time.process_time()\n",
    "print(f\"Delta {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unknown_words_with_sets(vocab:list, book_words:list):\n",
    "    # Use linear search\n",
    "    results = list(set(book_words).difference(set(vocab)))\n",
    "    # use sets for the resul\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta 0.00784835400000361\n"
     ]
    }
   ],
   "source": [
    "### now let's check the difference between our previous linear algo and the new algo\n",
    "start = time.process_time() \n",
    "find_unknown_words_with_sets(vocab, alice_words)\n",
    "end = time.process_time()\n",
    "print(f\"Delta {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(sequence, target):\n",
    "    pass\n",
    "    lower_bound = 0\n",
    "    higher_bound = len(sequence)\n",
    "    while True:\n",
    "        if lower_bound == higher_bound:\n",
    "            return -1\n",
    "        mid_index = (lower_bound  + higher_bound) // 2\n",
    "        \n",
    "    # Stop condition?\n",
    "    # How do we know we didn't find it?\n",
    "    # How should we focus the Region Of interest?\n",
    "\n",
    "# lets try to visualize this kind o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_binary(xs, target):\n",
    "    \"\"\" Find and return the index of key in sequence xs \"\"\"\n",
    "    lb = 0\n",
    "    ub = len(xs)\n",
    "    while True:\n",
    "        if lb == ub:   # If region of interest (ROI) becomes empty\n",
    "           return -1\n",
    "\n",
    "        # Next probe should be in the middle of the ROI\n",
    "        mid_index = (lb + ub) // 2\n",
    "        # Do I have a stopping point here?\n",
    "        # Fetch the item at that position\n",
    "        item_at_mid = xs[mid_index]\n",
    "\n",
    "        # print(\"ROI[{0}:{1}](size={2}), probed='{3}', target='{4}'\"\n",
    "        #       .format(lb, ub, ub-lb, item_at_mid, target))\n",
    "\n",
    "        # How does the probed item compare to the target?\n",
    "        if item_at_mid == target:\n",
    "            return mid_index      # Found it!\n",
    "        if item_at_mid < target:\n",
    "            lb = mid_index + 1    # Use upper half of ROI next time\n",
    "        else:\n",
    "            ub = mid_index        # Use lower half of ROI next time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unknown_words_binary(vocab:list, book_words:list):\n",
    "    # Use linear search\n",
    "    result = []\n",
    "    for word in book_words:\n",
    "        \n",
    "        if search_binary(vocab, word) < 0: \n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta 0.1484422249999966\n"
     ]
    }
   ],
   "source": [
    "### now let's check the difference between our previous linear algo and the new algo\n",
    "start = time.process_time() \n",
    "find_unknown_words_binary(vocab, alice_words)\n",
    "end = time.process_time()\n",
    "print(f\"Delta {end-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing adjacent duplicates from a list\n",
    "\n",
    "Given a list where some adjacent items are the same, remove adjacent (and only adjacent) items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 2, 7, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "def remove_adjacent(a_list:list) -> list:\n",
    "    results = []\n",
    "    last_item = None\n",
    "    for item in a_list:\n",
    "        if item != last_item:\n",
    "            results.append(item)\n",
    "            last_item = item\n",
    "    return results\n",
    "\n",
    "# What is the O complexity?\n",
    "# What is the \"memory usage\" ?\n",
    "sample = [1,1,2, 4, 2, 2,7,7,8,7,7]\n",
    "print(remove_adjacent(sample))\n",
    "assert remove_adjacent(sample) == [1,2, 4, 2, 7, 8, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### What would happen if the list was sorted? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lists(a_sorted_list_1: list, a_sorted_list_2:list)-> list:\n",
    "    \"\"\"\n",
    "    Gets two sorted lists, returns a sorted list\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# What's the problem with the immediate answer? (what is the immediate answer)\n",
    "# Can we think of an algorithemic \" divide conquer\" solution? \n",
    "# What is the smallest step possible here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging sorted lists as a general problem\n",
    "\n",
    "How can we adapt this algo to \n",
    "\n",
    "* Return only those items that are present in both lists.\n",
    "\n",
    "* Return only those items that are present in the second list, but not in the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to alice with merge sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and play more with algorithms\n",
    "\n",
    "https://www.khanacademy.org/computing/computer-science/algorithms\n",
    "\n",
    "Most of this tutorial was \"borrowed\" from [here](http://openbookproject.net/thinkcs/python/english3e/list_algorithms.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
